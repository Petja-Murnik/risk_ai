{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, log_loss\n",
    "\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "\n",
    "from risk_learning.config import filenames\n",
    "from risk_learning.risk_learning import get_classifier_family_name\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(filenames.fake_churn_simple)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split off test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at records per year for time split\n",
    "df.groupby('year').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_churn_data_target(df):\n",
    "    split_year = 2015\n",
    "    test = df.loc[df['year']>=split_year, :]\n",
    "    train_validate = df.loc[df['year'] < split_year]\n",
    "    \n",
    "    data_train_validate = train_validate[[c for c in df.columns if c != 'churn']]\n",
    "    lb = LabelBinarizer()\n",
    "    target_train_validate = lb.fit_transform(train_validate['churn']).ravel()\n",
    "\n",
    "    data_test = test[[c for c in df.columns if c != 'churn']]\n",
    "    target_test = lb.transform(test['churn']).ravel()\n",
    "    \n",
    "    return data_train_validate, target_train_validate, data_test, target_test\n",
    "\n",
    "\n",
    "data_train_validate, target_train_validate, data_test, target_test = split_churn_data_target(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put preprocessing and model selection in a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChurnPipeline:\n",
    "    def __init__(self, data, target, mapper, test_size=0.25):\n",
    "        self._set_train_validate(data, target, test_size)\n",
    "        self.mapper = mapper\n",
    "        \n",
    "    def _set_train_validate(self, data, target, test_size):\n",
    "        X_train, X_validate, y_train, y_validate = train_test_split(\n",
    "            data, target, test_size=0.25, random_state=42, stratify=target\n",
    "        )\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_validate = X_validate\n",
    "        self.y_validate = y_validate\n",
    "        \n",
    "    def hyperparameter_grid_select(self, clf_family_dict, param_grid):\n",
    "        family_name = clf_family_dict.get('name')\n",
    "        print('Hyperparameter fitting for {}'.format(family_name))\n",
    "        clf_family = clf_family_dict.get('clf')\n",
    "    \n",
    "        pipe = Pipeline([\n",
    "            ('featurize', self.mapper),\n",
    "            (family_name, clf_family)\n",
    "            ])\n",
    "\n",
    "        # Hyperparameter search\n",
    "        clf_select = GridSearchCV(pipe, param_grid, iid=False, cv=5, refit=True)\n",
    "        # Fit for cross validation folds across hyperparameter values\n",
    "        clf_select.fit(self.X_train, self.y_train)\n",
    "        print(\"Best parameter (CV score=%0.3f): {}\".format(clf_select.best_score_))\n",
    "        print(clf_select.best_params_)\n",
    "\n",
    "        return clf_select\n",
    "    \n",
    "    def clf_validation_score(self, clf):\n",
    "        print('\\nEvaluate score on validation set')\n",
    "        res = clf.score(self.X_validate, self.y_validate)\n",
    "        return res\n",
    "    \n",
    "    def clf_log_loss(self, clf):\n",
    "        print('\\nEvaluate log-loss on validation set')\n",
    "        res = log_loss(clf.predict(self.X_validate), self.y_validate)\n",
    "        return res\n",
    "    \n",
    "    def clf_confusion_matrix(self, clf):\n",
    "        print('\\nEvaluate confusion matrix on validation set')\n",
    "        res = confusion_matrix(self.y_validate, clf.predict(self.X_validate))\n",
    "        return res\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "mapper = DataFrameMapper([\n",
    "    ('gender', LabelBinarizer()),\n",
    "    ('profession', LabelBinarizer()), \n",
    "])\n",
    "\n",
    "churn = ChurnPipeline(data_train_validate, target_train_validate, mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "clf_family_dict = {\n",
    "    'name': 'lr',\n",
    "    'clf': LogisticRegression(solver='lbfgs', fit_intercept=True)\n",
    "}\n",
    "param_grid = {clf_family_dict.get('name') + '__C': np.logspace(1, 3, 20)}\n",
    "\n",
    "lr_clf = churn.hyperparameter_grid_select(clf_family_dict, param_grid)\n",
    "print(churn.clf_validation_score(lr_clf))\n",
    "print(churn.clf_log_loss(lr_clf))\n",
    "print(churn.clf_confusion_matrix(lr_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree\n",
    "clf_family_dict = {\n",
    "    'name': 'dt',\n",
    "    'clf': tree.DecisionTreeClassifier()\n",
    "}\n",
    "param_grid = {\n",
    "    clf_family_dict.get('name') + '__max_depth': range(1, 10, 1)\n",
    "}\n",
    "dt_clf = churn.hyperparameter_grid_select(clf_family_dict, param_grid)\n",
    "print(churn.clf_validation_score(dt_clf))\n",
    "print(churn.clf_log_loss(dt_clf))\n",
    "print(churn.clf_confusion_matrix(dt_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosted Trees\n",
    "clf_family_dict = {\n",
    "    'name': 'gbc',\n",
    "    'clf': GradientBoostingClassifier()\n",
    "}\n",
    "param_grid = {\n",
    "    clf_family_dict.get('name') + '__n_estimators': range(5, 10, 1)\n",
    "}\n",
    "\n",
    "gbc_clf = churn.hyperparameter_grid_select(clf_family_dict, param_grid)\n",
    "print(churn.clf_validation_score(gbc_clf))\n",
    "print(churn.clf_log_loss(gbc_clf))\n",
    "print(churn.clf_confusion_matrix(gbc_clf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More complicated churn data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filenames.fake_churn)\n",
    "data_train_validate, target_train_validate, data_test, target_test = split_churn_data_target(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "mapper = DataFrameMapper([\n",
    "    ('gender', LabelBinarizer()),\n",
    "    (['age'], StandardScaler()),\n",
    "    ('profession', LabelBinarizer()), \n",
    "])\n",
    "\n",
    "churn = ChurnPipeline(data_train_validate, target_train_validate, mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "clf_family_dict = {\n",
    "    'name': 'lr',\n",
    "    'clf': LogisticRegression(solver='lbfgs', fit_intercept=False)\n",
    "}\n",
    "param_grid = {clf_family_dict.get('name') + '__C': np.logspace(-4, 2, 20)}\n",
    "\n",
    "lr_clf = churn.hyperparameter_grid_select(clf_family_dict, param_grid)\n",
    "print(churn.clf_validation_score(lr_clf))\n",
    "print(churn.clf_log_loss(lr_clf))\n",
    "print(churn.clf_confusion_matrix(lr_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree\n",
    "clf_family_dict = {\n",
    "    'name': 'dt',\n",
    "    'clf': tree.DecisionTreeClassifier()\n",
    "}\n",
    "param_grid = {\n",
    "    clf_family_dict.get('name') + '__max_depth': range(1, 10, 1)\n",
    "}\n",
    "dt_clf = churn.hyperparameter_grid_select(clf_family_dict, param_grid)\n",
    "print(churn.clf_validation_score(dt_clf))\n",
    "print(churn.clf_log_loss(dt_clf))\n",
    "print(churn.clf_confusion_matrix(dt_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosted Trees\n",
    "clf_family_dict = {\n",
    "    'name': 'gbc',\n",
    "    'clf': GradientBoostingClassifier()\n",
    "}\n",
    "param_grid = {\n",
    "  #  clf_family_dict.get('name') + '__min_samples_leaf': range(3,10),\n",
    "    clf_family_dict.get('name') + '__n_estimators': range(5, 10, 1)\n",
    "}\n",
    "\n",
    "gbc_clf = churn.hyperparameter_grid_select(clf_family_dict, param_grid)\n",
    "print(churn.clf_validation_score(gbc_clf))\n",
    "print(churn.clf_log_loss(gbc_clf))\n",
    "print(churn.clf_confusion_matrix(gbc_clf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
