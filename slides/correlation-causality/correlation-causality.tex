% Input common header
\input{../ai_for_risk_header}


\title{Correlation and Causality}
\begin{document}
\maketitle

\begin{frame}
\frametitle{Why causality matters}

   \centering
    \begin{tikzpicture}
 
    \node[inner sep=0pt] (proxy_caption) at (0,0){
        Because correlation is a proxy.
    };

    \node[inner sep=0pt, below=0.5 of proxy_caption] (proxy) at (0,0) {
        \fbox{
            \includegraphics[width=.75\textheight]{graphics/spiders_spelling}
        }
    };
  
\end{tikzpicture}

\cite{spurious-spiders-spelling}
\end{frame}

\begin{frame}
\frametitle{Why causality matters}
\centering
\begin{tikzpicture}

    \node[inner sep=0pt] (med_caption) at (0,0) {
            Because A / B testing is not always possible.
    };
    \node[inner sep=0pt, below=0.5cm of med_caption] (med)  {
        \fbox{
            \includegraphics[width=.9\textheight]{graphics/mediterranean}
        }
    };
     
\end{tikzpicture}

\cite{estruch2013primary}
\end{frame}


\begin{frame}
    \frametitle{Simpson's paradox: cautionary tales}
    Simpson's paradox: a phenomenon in probability and statistics in which a trend appears disappears or reverses depending on grouping of data. \cite{simpson-wikipedia} \newline
    
    Example: University of California, Berkeley 1973 admission figures\newline
    
    \begin{figure}[ht]
        \includegraphics[height=0.15\textheight]{graphics/berkeley}\newline
        \cite{freedman1998statistics}
    \end{figure}
    \begin{figure}[ht]
        \includegraphics[height=0.3\textheight]{graphics/berkeley_later}\newline
        \cite{Bickel398}
    \end{figure}
    
\end{frame}


\begin{frame}
\frametitle{A brief, biased history of causality}
\begin{itemize}
\item Aristotle, 384 - 322 BC
\item Isaac Newton, 1643 - 1727 AD
\item David Hume, 1711 - 1776 AD
\item Francis Galton, 1822 - 1900 AD, Karl Pearson, 1857 - 1936 AD
\item Judea Pearl, b. 1936 AD
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{Counterfactuals and causality}
Ideal: Intervention + \href{https://en.wikipedia.org/wiki/Multiverse}{Multiverse} $\rightarrow$ Causality\newline

Examples:
\begin{itemize}
\item Medical treatment (e.g. \href{https://en.wikipedia.org/wiki/Simpson\%27s_paradox\#Kidney_stone_treatment}{kidney stone treatment})
\item Social outomes (e.g. \href{https://en.wikipedia.org/wiki/Simpson\%27s_paradox\#UC_Berkeley_gender_bias}{university admissions})
\item Business outcomes (e.g. \href{https://en.wikipedia.org/wiki/Click-through\_rate}{click-through rate}, hit rate)\newline
\end{itemize}

In-practice:
\begin{itemize}
    \item Correlation: approximate multiverse by comparing intervention at $t$ to result at $t-1$
    \item Random population: approximate multiverse by splitting sample well
    \item A / B testing: random populations A / B + intervention in one
\end{itemize}
\end{frame}




\begin{frame}
\frametitle{Counterfactual example: hit rate for insurance}
Variables:
\begin{itemize}
\item product\_type: Client line of business
\item days: Number of days to generate quote
\item rating: Binary indication of client risk
\item hit: Binary, 1 for success (binding the quote), 0 for failure\newline
\end{itemize}

Fake data:\newline\newline
\input{../ai-for-risk/graphics/hits}\newline
\end{frame}


\begin{frame}
    \frametitle{Counterfactual example: hit rate for insurance}
    Variables:
    \begin{itemize}
    \item product\_type: Client line of business
    \item days: Number of days to generate quote
    \item rating: Binary indication of client risk
    \item hit: Binary, 1 for success (binding the quote), 0 for failure\newline
    \end{itemize}
    
    \begin{figure}[ht]
    \includegraphics[height=0.6\textheight]{graphics/hit}
    \end{figure}
\end{frame}


\begin{frame}
    \frametitle{The Structural Causal Model}
    The definitions in following slides are from \cite{pearl2007mathematics}.

    A \emph{structural causal model} $M$ consists of two sets of variables $U, V$ and a set of functions $F$, where 
    
    \begin{itemize}
        \item $U$ are considered \emph{exogenous}, or background variables, 
        \item $V$ are the \emph{causal} variables, i.e. that can be manipulated, and
        \item $F$ are the functions that represent the process of assigning values to elements of $V$ based on other values in $U, V$, e.g. $v_i = f(u, v)$.
    \end{itemize}

    We denote by $G$ the graph induced on $U, V$ by the functions $F$, and call it the \emph{causal graph} of $(U, V, F)$.
\end{frame}

\begin{frame}
    \frametitle{The definition of ``do"}
\end{frame}
\begin{frame}
\frametitle{Judea Pearl's Rules of Causality}

Let $X$, $Y$ , $Z$ and $W$ be arbitrary disjoint sets of nodes in a DAG $G$. Let $G_\underline{X}$ be the graph obtained by removing all arrows pointing into (nodes of) $X$. 
Denote by $G_{\overline{X}}$ the graph obtained by removing all arrows pointing out of $X$. If, e.g. we remove arrows pointing out of $X$ and into $Z$, we the resulting graph is denoted by $G_{\underline{X} \overline{Z}}$

Rule 1: Insertion / deletion of observations
\begin{equation*}
P(y | \jpdo(x), z, w) = P(y | \jpdo(x), w) \textrm{ if } (Y \ci Z | X, W)_{G_{\overline{X}}}
\end{equation*}

Rule 2: Action / observation exchange
\begin{equation*}
P(y | \jpdo(x), \jpdo(z), w) = P(y | \jpdo(x), z, w) \textrm{ if } (Y \ci Z | X, W)_{G_{\overline{X} \underline{Z}}}
\end{equation*}

Rule 3: Insertion / deletion of actions
\begin{equation*}
P(y | \jpdo(x), \jpdo(z), w) = P(y | \jpdo(x), w) \textrm{ if } (Y \ci Z | X, W)_{G_{\overline{X} \overline{Z(W)}}},
\end{equation*}

where $Z(W)$ is the set of $Z$-nodes that are not ancestors of any $W$-node in $G_\underline{X}$.

\end{frame}

\begin{frame}
\frametitle{Special cases of the causal rules}

By judicious setting of sets of nodes to be empty, we obtain some useful corollaries of the causal rules.
\newline

Rule 1': Insertion / deletion of observations, with $W = \emptyset$
\begin{equation*}
    P(y | \jpdo(x), z) = P(y | \jpdo(x)) \textrm{ if } (Y \ci Z | X)_{G_{\overline{X}}}
\end{equation*}

Rule 2': Action / observation exchange, with $X = \emptyset$
\begin{equation*}
P(y | \jpdo(z), w) = P(y | z, w) \textrm{ if } (Y \ci Z | W)_{G_{ \underline{Z}}}
\end{equation*}

Rule 3': Insertion / deletion of actions, with $X, W = \emptyset$
\begin{equation*}
P(y | \jpdo(z)) = P(y) \textrm{ if } (Y \ci Z )_{G_{\overline{Z}}}
\end{equation*}

\end{frame}

\begin{frame}[allowframebreaks]
    \frametitle{References}
    \setbeamertemplate{bibliography item}[text]
    \bibliographystyle{amsalpha}
    \bibliography{../../references.bib}
\end{frame}

\end{document}